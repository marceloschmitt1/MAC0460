{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regressão linear 1: equações normais\n",
    "\n",
    "\n",
    "Dado o dataset $(\\mathbf{x}_{1}, y_{1}), \\dots ,(\\mathbf{x}_{N}, y_{N})$ onde $\\mathbf{x}_i \\in \\mathbb{R}^{d}$ e $y_i \\in \\mathbb{R}$, podemos aproximar a função desconhecida $f:\\mathbb{R}^{d} \\rightarrow \\mathbb{R}$ (lembrando que $y_i =f(\\mathbf{x}_i)$) por meio de um modelo linear $h$:\n",
    "$$\n",
    "h(\\mathbf{x}_{i}; \\mathbf{w}, b) = \\mathbf{w}^\\top  \\mathbf{x}_{i} + b\n",
    "$$\n",
    "\n",
    "Note que $h(\\mathbf{x}_{i}; \\mathbf{w}, b)$ é na verdade uma [transformação afim](https://en.wikipedia.org/wiki/Affine_transformation) de $\\mathbf{x}_{i}$. Como em outros lugares, vamos usar o termo \"linear\" também para caracterizar uma transformação afim.\n",
    "\n",
    "A saída de $h$ é uma transformação linear de $\\mathbf{x}_{i}$. Usamos a notação $h(\\mathbf{x}_{i}; \\mathbf{w}, b)$ para deixar claro que $h$ é um modelo parametrizado, i.e., a transformação $h$ é definida pelos parâmetros $\\mathbf{w}$ e $b$. Podemos pensar no vetor $\\mathbf{w}$ como um vetor de *pesos* controlando o efeito de cada *feature* na predição.\n",
    "\n",
    "Adicionando uma feature a mais na obsevação $\\mathbf{x}_{i}$ (com o valor 1) -- coordenada artificial -- podemos simplificar a notação do modelo:\n",
    "\n",
    "$$\n",
    "h(\\mathbf{x}_{i}; \\mathbf{w}) = \\hat{y}_{i} = \\mathbf{w}^\\top  \\mathbf{x}_{i}\n",
    "$$\n",
    "\n",
    "Procuramos os melhores parâmetros $\\mathbf{w}$ de modo que a predição $\\hat{y}_{i}$ seja a mais próxima de $y_{i}$ de acordo com alguma métrica de erro. Usando o *erro quadrárico médio* como tal métrica podemos obter a seguinte função de custo:\n",
    "\n",
    "\\begin{equation}\n",
    "J(\\mathbf{w}) = \\frac{1}{N}\\sum_{i=1}^{N}(\\hat{y}_{i} - y_{i})^{2}\n",
    "\\end{equation}\n",
    "\n",
    "Desse modo, a tarefa de achar os parâmetros $\\mathbf{w}$ se torna a tarefa de encontrar os valores de $\\mathbf{w}$ para minimizar $J(\\mathbf{w})$.\n",
    "\n",
    "**Aqui vamos começar a explorar esse modelo olhando para um dataset bem simples**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all imports\n",
    "import numpy as np\n",
    "import time\n",
    "from util import get_housing_prices_data, r_squared\n",
    "from plots import plot_points_regression \n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### O dataset\n",
    "\n",
    "Os dados que vamos trabalhar vão ser dados artificiais. Vamos pegar 100 observações com apenas uma *feature* (metros quadrados de um imóvel) e com isso vamos associar um valor (o preço desse imóvel em $). Nossa tarefa é construir um modelo que consiga predizer o valor de imóveis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = get_housing_prices_data(N=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotando os dados\n",
    "\n",
    "Acima temos algumas informações sobre os dados, podemos também visualizar cada ponto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_points_regression(X,\n",
    "                       y,\n",
    "                       title='Real estate prices prediction',\n",
    "                       xlabel=\"m\\u00b2\",\n",
    "                       ylabel='$')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Equações normais\n",
    "\n",
    "Dados $f:\\mathbb{R}^{n\\times m} \\rightarrow \\mathbb{R}$ e $\\mathbf{A} \\in \\mathbb{R}^{n\\times m}$, definimos a derivada de $f$ com respeito a $\\mathbf{A}$ como:\n",
    "\n",
    "\\begin{equation*}\n",
    "\\nabla_{\\mathbf{A}}f =  \\begin{bmatrix}\n",
    "\\frac{\\partial f}{\\partial \\mathbf{A}_{1,1}} & \\dots & \\frac{\\partial f}{\\partial \\mathbf{A}_{1,m}} \\\\\n",
    "\\vdots &  \\ddots & \\vdots \\\\\n",
    "\\frac{\\partial f}{\\partial \\mathbf{A}_{n,1}} &  \\dots & \\frac{\\partial f}{\\partial \\mathbf{A}_{n,m}}\n",
    "\\end{bmatrix}\n",
    "\\end{equation*}\n",
    "\n",
    "Seja $\\mathbf{X} \\in \\mathbb{R}^{N\\times m}$ a matriz cujas linhas são as observações do dataset (também chamada de *design matrix*) e seja $\\mathbf{y} \\in \\mathbb{R}^{N}$ o vetor contendo todos os valores de $y_{i}$ (i.e., $\\mathbf{X}_{i,:} = \\mathbf{x}_{i}$ e $\\mathbf{y}_{i} =y_{i}$). É fácil checar que: \n",
    "\n",
    "\n",
    "\\begin{equation}\n",
    "J(\\mathbf{w}) = \\frac{1}{N}(\\mathbf{X}\\mathbf{w} - \\mathbf{y})^{T}(\\mathbf{X}\\mathbf{w} - \\mathbf{y})\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "Usando certos conceitos básicos de derivada com matrizes podemos chegar no gradiente de $J(\\mathbf{w})$ com respeito a $\\mathbf{w}$\n",
    "\n",
    "\\begin{equation}\n",
    "\\nabla_{\\mathbf{w}}J(\\mathbf{w}) = \\frac{2}{N} (\\mathbf{X}^{T}\\mathbf{X}\\mathbf{w} -\\mathbf{X}^{T}\\mathbf{y})   \n",
    "\\end{equation}\n",
    "\n",
    "Assim, quando $\\nabla_{\\mathbf{w}}J(\\mathbf{w}) = 0$ temos que \n",
    "\n",
    "\\begin{equation}\n",
    "\\mathbf{X}^{T}\\mathbf{X}\\mathbf{w} = \\mathbf{X}^{T}\\mathbf{y}\n",
    "\\end{equation}\n",
    "\n",
    "Desse modo,\n",
    "\n",
    "\\begin{equation}\n",
    "\\mathbf{w} = (\\mathbf{X}^{T}\\mathbf{X})^{-1}\\mathbf{X}^{T}\\mathbf{y}\n",
    "\\end{equation}\n",
    "\n",
    "A solução dada por essas equações são conhecidas como **equações normais**. Note que esse tipo de solução tem um custo, pois conforme cresce o número de variáveis, o tempo da inversão da matriz fica proibitivo. Vale a pena ler [esse material](http://cs229.stanford.edu/notes/cs229-notes1.pdf) para ver o argumento com mais detalhes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercício\n",
    "Implemente a predição usando o método de equações normais. Usando apenas a biblioteca **numpy** você deve completar a função abaixo (uma introdução rápida a certas funcionalidades dessa biblioteca pode ser encontrada [aqui](http://cs231n.github.io/python-numpy-tutorial/)). Lembre que $\\mathbf{X} \\in \\mathbb{R}^{N\\times d}$, você precisa adicionar uma componente com apenas 1s a cada observação em $\\mathbf{X}$ e realizar a computação descrita acima."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normal_equation_prediction(X, y):\n",
    "    \"\"\"\n",
    "    Calculates the prediction using the normal equation method.\n",
    "    You should add a new row with 1s.\n",
    "\n",
    "    :param X: design matrix\n",
    "    :type X: np.ndarray(shape=(N, d))\n",
    "    :param y: regression targets\n",
    "    :type y: np.ndarray(shape=(N, 1))\n",
    "    :return: prediction\n",
    "    :rtype: np.ndarray(shape=(N, 1))\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE:\n",
    "    raise NotImplementedError(\"falta completar a função normal_equation_prediction\")\n",
    "    # END YOUR CODE\n",
    "    return prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = normal_equation_prediction(X, y)\n",
    "r_2 = r_squared(y, prediction)\n",
    "plot_points_regression(X,\n",
    "                       y,\n",
    "                       title='Real estate prices prediction',\n",
    "                       xlabel=\"m\\u00b2\",\n",
    "                       ylabel='$',\n",
    "                       prediction=prediction,\n",
    "                       legend=True,\n",
    "                       r_squared=r_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Você pode usar a métrica [$R^2$](https://pt.wikipedia.org/wiki/R%C2%B2) para ver o quão bem o modelo linear está se ajustando aos dados.\n",
    "\n",
    "**Nesse caso $R^2$ tem que estar próximo de $0.5$.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = get_housing_prices_data(N=1000000, verbose=False)\n",
    "init = time.time()\n",
    "prediction = normal_equation_prediction(X, y)\n",
    "init = time.time() - init\n",
    "print(\"Tempo de execução da função de predição = {:.8f}(s)\".format(init))\n",
    "print(\"Tem que ser em menos de 1 segundo \")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
